Skeleton of the lecture micrograd. I plan to use this in order to build it from scratch on my own.
Derivatives
- derivative of a function, chain rule, backpropagation, write notes
- get derivatives of a complex function if possible, here the derivatives should be written in terms of computation graphs
- sketch out these functions to understand what these functions are doing

Data Structure for the simple micrograd object
- add a class Value, init with just the data, repr, add and mul methods
- after this basic ops, we need to create a children, prev
- how would you initialize these? we need pointers to children from curr and pointer to curr from children. we also need to know what op is connecting them
- draw this computation graph (is there a better way than draw dot?) - learn a little about graphviz
- at this point give them labels (is there a better way to visualise them, wrt to the name of the variable, instead of label)
- for consistency use the formula, L = d * f; e = a*b; d = e+c; a= 2, b=-3, c=10, f=-2
- the nodes of the graph here indicate the weights of the NN? why?
- also do you understand what is the difference between a normal function and building out this funtion using a computational graph? 
why is this approach better? (works on a comp better than using direct math/a function? any other reason?)
- why does chain rule work? do you understand the intuition behind it? its basically multiplying the rates of change
- at this point you'd need self.grad to store the gradient of the current node (gradient of the current node wrt to the last node)
- (YOU HAVE A PRESENTATION DUE TOMO, STOP WATCHING LECTURES PLIS)
- skip the manual part of creating the grad on your own and write the code for it
- oooo mult swaps the grad values of children to the node value, why? use function xy to visualise this
- what is gradient check? 
- addition routes the gradient from parents to children whereas mult swaps then gradients with the node value of the other child 
- mult kinda couples the children together, addition doesn't (couples the gradients not the nodes?)
- when you nudge the variable in the direcion of the gradient the function value increases, why because the definition - gradient is rate of change of function with increase in variable
- (learn a little about why hyperbolic function were created? and why they have such weird derivatives, for lols)
- what does autograd mean btw?
- gradient of the function also gives the direction of steepest ascent, why? because the gradient is the direction of the fastest increase of the function
- write out the expression graph for o = tanh(x1w1 + x2w2 + b) and then write out the gradients for each of the variable, show it in the draw dot
- at any point in the computation graph, the gradient is local gradient * gradient of the parent node (chain rule)
- (check how pytorch does this, how does it store the gradients? how does it store the computation graph? how does it calculate the gradients?)
- at this point you need to write out what will be the _backward function for __add__, __mul__, tanh, also note that at no point are we doing something like z = 2x + y etc, here 2 would add additional factor
- so what _backward does here is *push* the gradients to the children, ofcourse it makes sure the children contrubute as well, such a sweet(?) parent
- at this point you'd have to call the _backward function manually for each node
- how do you automate it?
- you need to create a function that does a topological sort on the graph and calls the _backward function on each node
- why topo sort - cuz you'd want the edges to be traversed in one direction. (side note: please study graph theory again)
- write the topo sort algo by yourself plis, also reversed topo - how is this a unique list? it shouldnt be?
- at this point you need to write an actual backward function inside the class to call topo and apply backward on the output node
- if variable is used more than once, you need to add the gradients, otherwise you'd rewrite it. how would you figure this out? why does this work? because you have accumulative effects on the computational graph when you use the same variable multiple times
- multivariate grads
- wrapping other in the Value, using __rmul__ and __radd__ to make sure that the Value is always on the left side of the operator
- hmmm now we break down tanh into exp components and write backward for it 
- instead of division, we implement x ** k, youd implement __pow__ at this point and also have a backward function here
- basically every function until now will have _backward function in it
- subtraction - implement sub = add of neg
- at this point get a feel of what pytorch does. we are going to use pytorch and cast it into double, we need to make requires_grad = True for the variables
- diff between o.item() vs o.data.item()
- learn what zip() does, seems to be used in multiple leetcodes as well
- what is activation function? it is a function that takes in a weighted sum of the inputs and outputs a value between 0 and 1
- initialise a Neuron, Layer and a MLP using Pytorch
- example x = [2,3,-1] n = MLP(3, [4, 4,1]); use this to construct the MLP
- oh looks like +, - etc of a pytorch tensor with a float return tensor - does this have cummulative property?
- why do we generally use MSE loss? because it is differentiable and convex - why not somehting else?
- draw this loss, this is so crazy
-  not only weight, but also biases can be updated - i think i knew this, but i forgot
- we need the loss function to decrease, not increase, hence we need to nudge the weights in the opposite direction of the gradient
- 